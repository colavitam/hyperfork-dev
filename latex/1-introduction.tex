% !TEX root = top.tex above command is so that compilation is always from
% top.tex
\section{Introduction} \label{sec:intro}

\Paragraph{Serverless Computing} Serverless computing, also known as
\emph{Function-as-a-Service} (FaaS), has become an increasingly prevalent
platform in the cloud computing ecosystem. In an attempt to realize a vision of
computation as a utility, serverless computing allows users to run application
code in response to triggers without provisioning infrastructure. In comparison
to current cloud computing platforms, clients no longer have to maintain
virtual machine images, are billed only for application computation performed
in response to requests, and benefit from autoscaling to handle variable
request rates.~\cite{berkeley-serverless} Platforms are available from all major
cloud computing vendors, including Amazon Lambda~\cite{lambda}, Azure
Functions~\cite{azure-cf}, and Google Cloud Functions~\cite{gcf}. Several
significant enterprise customers have moved parts of their services onto
serverless platforms, including the news site The Guardian~\cite{guardian}.
Serverless computing is currently an active area of research, with many
performance and theoretical improvements to be
made~\cite{peeking}\cite{trilemma}\cite{steps-back}.

\Paragraph{Serverless Infrastructure} The typical implementation of a
serverless computing platform places user-submitted functions onto dynamically
created virtual machines (VMs). These functions are intended to be light-weight
stateless programs. Because of the relatively short run-times of serverless
functions, a critical performance constraint in serverless infrastructure
implementations is the scheduling latency of functions---mainly comprised of
the creation time for instance VMs. A standard optimization employed for
start-up time is to keep instance VMs running for a period of time, and
schedule function requests onto existing VMs. Another property is the clear
split in individual function start-up latencies between \emph{warm-starts}, in
which a function is scheduled to an already running instance, and
\emph{cold-starts}, in which a new VM must be created for the function.
Functions from different customers are usually not placed in the same VM for
security and isolation reasons, but one VM can host several instances of one
customer's function.

\Paragraph{Cold-start Latency} A central promise of serverless computing
services is rapid scalability. Meeting this demand at scale requires that new
function instances can be rapidly started to service incoming requests. This is
easy when there remain available warm instances, but is more difficult when a
new cold instance must be started. Prevous work has recorded Amazon Lambda
warm-start latencies of around 25ms, and cold-start latencies of
250ms~\cite{peeking}.

For cold-start, one significant bottleneck is the boot time of a new VM. In the
Amazon Firecracker specification~\cite{firecracker-spec}, new VMs are
benchmarked to boot in about 125ms, a significant portion of cold-start
latency. To improve cold-start latencies, reductions in VM creation times are
needed. To create a VM, the host hypervisor and virtual machine Monitor (VMM)
must initialize virtual resources including vCPUs, memory, and other devices,
then the guest kernel must be loaded from disk and initialized in guest memory.
The guest kernel will then boot, and finally the function runtime can be
started and the request handled.

\Paragraph{Flash Cloning} Three significant parts of VM creation include (1)
loading the kernel into memory, (2) booting the guest kernel, and (3) loading
potentially large libraries and runtimes. Management operations within the VMM
such as virtual device creation and resource allocation are relatively cheap
compared to a guest's boot time. Optimizing these steps could dramatically
reduce the startup latency of new serverless functions. One technique to do so
is to employ \emph{flash cloning}. Instead of loading VM images from disk and
booting a kernel, we propose cloning existing reference VMs in memory.
Additionally, we propose a copy-on-write mechanism to reduce both the copy time
and the memory pressure of packing many VMs onto one host. This method can be
compared to the Unix fork abstraction.

\Paragraph{HyperFork} To create a new, isolated virtual machine, we propose to
re-create only the necessarily distinct VMM components while cloning
initialized guest memory and execution context pre-booted virtual machines.
From this insight we present \emph{HyperFork}, a KVM-based VM cloning
implementation for serverless computing. We demonstrate that HyperFork
outperforms standard VM creation latencies by up to two orders of magnitude. We
further present a thorough analysis of the potential performance degradation
due to copy-on-write memory sharing. We further demonstrate that
latency-sensitive workloads display a marked improvement in overall resource
utilization without degraded performance.

Our implementation is open source and available on Github at
\href{https://github.com/colavitam/hyperfork-kvmtool}{colavitam/hyperfork-kvmtool}.

The rest of the paper is organized as follows. Section~\ref{sec:related}
provides a summary of related work. Section~\ref{sec:background} describes the
technologies HyperFork is built upon. Section~\ref{sec:implementation}
describes the design and architecture of HyperFork. We evaluate its performance
in Section~\ref{sec:evaluation}, and discuss the results in
Section~\ref{sec:discussion}. We conclude by outlining our implementation's
current limitations and directions for further research.
