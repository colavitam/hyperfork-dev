% !TEX root = top.tex
% above command is so that compilation is always from top.tex
\section{Experimental Evaluation} \label{sec:experiments}
This is the experiments section
First summarize the findings in an implicit way. For example:
``In this section, we demonstrate that System X achieves Z, Y, K''
where Y, Z, K are our main contributions in the paper as well.

\Paragraph{Experimental Setup}
The experimental setup includes information about the following 5 things:
(i) \textit{Experimental Platform}, i.e., the machine we used,
(ii) \textit{Implementation}, i.e., whether it is a prototype system, based on an existing one, and any other relevant detail,
(iii) \textit{Configuration}, i.e., the system-specific configuration and tuning that might have been needed, and discuss the possible values for any parameter.
(iv) \textit{Workloads}, i.e., dataset characteristics, and query characteristics, and (unless the whole paper is a single experiment this here just gives a summary of the workloads used and each experiment later on gives the exact setup)
(v) \textit{Metrics}, typically latency and/or throughput with some details and the
methodology.

For the experimental platform we do
not want to use exactly the same phrasing in every paper, however, the content should
be the same.

We perform all tests on [SOME MACHINE], with [SOME SPECS].

\subsection{Benchmarks}

\Paragraph{Fork Time} We run several experiments to test the time for a VM to fork. These tests start a virtual machine, allocate some memory, and then fork. The forking process marks a timestamp when its fork() call returns, and the child marks a timestamp once it finishes restoring KVM state.

Even though memory is not copied to the child process unless it is written, it still takes time to walk through the parent page table and mark shared memory as read-only, and generate page tables for the child process. For this reason we expect to see fork times scale roughly linearly with the amount of memory allocated pre-fork. Allocating more memory simulates a VM with more programs and libraries loaded. [FIGURE: fork time in parent and child vs amount of memory allocated pre-fork]

\Paragraph{Copy-on-Write Test} Though cloning VMs using Fork can decrease VM start times by orders of magnitude because of shared memory, performing Copy-on-Write on those shared regions has the potential to reduce performance. We implement a benchmark to isolate the performance degradation caused by Copy-on-Write operations after cloning.

This program begins by allocating many pages of memory, and writing a small amount of random data to each one. It then signals to the host, which forks the VM $n$ times. In each child the program then writes more random data to each of those pages.

\Paragraph{Real-world Conditions} In the lifecycle of a typical Function-as-a-Service unit, a VM is started, code and data are copied on, and the user function is run. These services mostly use runtimes like NodeJS or Python. To simulate this sort of workload, we use pillow-perf, a Python image processing benchmark. We compare the total time of starting $n$ separate VMs, and letting each run the benchmark to completion, with the total time of forking $n$ VMs from one reference image and letting them run to completion. [TODO: fork at different times]

The CPU performance of forked VMs should not differ from separately booted VMs. Using a CPU-bound benchmark like pillow-perf verifies this assumption.

\Paragraph{Explaining Each Figure}
We first put the most important figures, i.e., the
ones that have the most important results in terms
of the contributions. Each figure should be a
single message. Each figure comes with two
paragraphs. One paragraph for the setup and one
paragraph for the discussion. The set-up paragraph
should start by saying ``In this experiment we
show that... We setup this experiment as follows...''.

The result paragraph explains in detail why we see
what we see. Explanations should be based on facts
and logic. Numbers that back up the explanations
should be provided whenever possible. The
paragraph should finish by repeating the main
message again.
